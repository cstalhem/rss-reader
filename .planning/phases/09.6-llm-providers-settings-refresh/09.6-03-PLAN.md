---
phase: 09.6-llm-providers-settings-refresh
plan: 03
type: execute
wave: 3
depends_on: ["09.6-02"]
files_modified:
  - frontend/src/components/settings/TopLevelModelSelector.tsx
  - frontend/src/components/settings/LLMProvidersSection.tsx
  - frontend/src/components/settings/ModelSelector.tsx
  - frontend/src/components/settings/OllamaSection.tsx
  - frontend/src/components/settings/OllamaHealthBadge.tsx
  - frontend/src/app/settings/ollama/page.tsx
autonomous: false
requirements:
  - OLLAMA-02
  - OLLAMA-05

must_haves:
  truths:
    - "User can search for models by name across all active providers via a grouped searchable dropdown"
    - "Model selector shows models grouped by provider name (e.g., 'Ollama' group header)"
    - "Separate-models toggle allows mix-and-match: different providers for categorization vs scoring"
    - "Save and Re-evaluate buttons work from the top-level model selector"
    - "Old OllamaSection.tsx and ModelSelector.tsx are deleted or repurposed (no dead code)"
    - "Old /settings/ollama route is removed or redirects to /settings/llm-providers"
  artifacts:
    - path: "frontend/src/components/settings/TopLevelModelSelector.tsx"
      provides: "Grouped Combobox model selector with search, save, rescore"
    - path: "frontend/src/components/settings/LLMProvidersSection.tsx"
      provides: "Updated orchestrator with TopLevelModelSelector at top"
  key_links:
    - from: "frontend/src/components/settings/TopLevelModelSelector.tsx"
      to: "frontend/src/hooks/useOllamaConfig.ts"
      via: "config state and save/rescore mutations"
      pattern: "useOllamaConfig|saveMutation|rescoreMutation"
    - from: "frontend/src/components/settings/TopLevelModelSelector.tsx"
      to: "@chakra-ui/react"
      via: "Combobox with useListCollection and useFilter"
      pattern: "Combobox|useListCollection|useFilter"
    - from: "frontend/src/components/settings/LLMProvidersSection.tsx"
      to: "frontend/src/components/settings/TopLevelModelSelector.tsx"
      via: "renders TopLevelModelSelector above provider pills"
      pattern: "TopLevelModelSelector"
---

<objective>
Replace the per-provider model dropdowns with a top-level grouped searchable Combobox selector, wire the complete save/rescore flow, clean up dead code, and verify the full page visually.

Purpose: The model selector is the primary user interaction on this page -- selecting which models to use for categorization and scoring across all providers. Replacing Select with Combobox adds search capability essential as model counts grow with multiple providers.
Output: Working grouped model selector with search, complete page flow verified, dead code removed.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09.6-llm-providers-settings-refresh/09.6-CONTEXT.md
@.planning/phases/09.6-llm-providers-settings-refresh/09.6-RESEARCH.md
@.planning/phases/09.6-llm-providers-settings-refresh/09.6-01-SUMMARY.md
@.planning/phases/09.6-llm-providers-settings-refresh/09.6-02-SUMMARY.md

@frontend/src/components/settings/LLMProvidersSection.tsx
@frontend/src/components/settings/ModelSelector.tsx
@frontend/src/components/settings/OllamaSection.tsx
@frontend/src/hooks/useOllamaConfig.ts
@frontend/src/hooks/useOllamaModels.ts
@frontend/src/hooks/useScoringStatus.ts
@frontend/src/lib/types.ts
@frontend/src/lib/utils.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: TopLevelModelSelector with grouped Combobox</name>
  <files>
    frontend/src/components/settings/TopLevelModelSelector.tsx
    frontend/src/components/settings/LLMProvidersSection.tsx
  </files>
  <action>
**TopLevelModelSelector.tsx** — New file. Replaces the old ModelSelector as the top-level model selection UI.

Uses Chakra Combobox with `useListCollection` and `useFilter` per research patterns.

Props:
- `models: OllamaModel[]` (from useOllamaModels — in future, this will be a union of all provider models)
- `config: OllamaConfig` (effective config with local edits)
- `savedConfig: OllamaConfig`
- `onConfigChange: (config: OllamaConfig) => void`
- `onSave: (rescore: boolean) => void`
- `isSaving: boolean`

Implementation:

1. **Build model items** for the collection: Map models to `{ label: "modelname — size (loaded)", value: "ollama:modelname", provider: "Ollama" }`. The value is prefixed with provider ID for uniqueness when multiple providers exist. Currently only Ollama models, but the structure supports future providers.

2. **useFilter + useListCollection**: Per research pattern:
   ```tsx
   const { contains } = useFilter({ sensitivity: "base" });
   const { collection, filter } = useListCollection({
     initialItems: modelItems,
     filter: contains,
     groupBy: (item) => item.provider,
   });
   ```

   **Reactivity note from research:** `useListCollection` uses `initialItems`. If models change (download/delete), the collection may not update. Handle this by passing a `key` prop on the Combobox parent keyed on `models.length` (or a hash) to force remount when models change. Test this during implementation — if `useListCollection` IS reactive to `initialItems` reference changes, the key prop is unnecessary.

3. **Combobox rendering**: Per research code example. Use `Portal > Positioner > Content` (Combobox follows Select portal rules, not Dialog). Render `collection.group()` for grouped display with `Combobox.ItemGroup` and `Combobox.ItemGroupLabel`.

4. **Separate models toggle**: `Switch.Root` for `use_separate_models`. When enabled, show two Comboboxes side by side (categorization + scoring) in a responsive Grid. When disabled, show one Combobox labeled "Model". Mix-and-match allowed per CONTEXT.md — different Comboboxes can select from different provider groups.

5. **Value mapping**: Current config stores bare model names (e.g., "qwen3:4b"). The Combobox values are prefixed ("ollama:qwen3:4b"). Need to:
   - Convert config model name to Combobox value on render: `"ollama:" + config.categorization_model`
   - Convert Combobox value back to model name on change: strip the prefix before calling `onConfigChange`
   - Handle the case where current model is not in the collection (model deleted while selected): include it as a "missing" item in the collection with a warning indicator

6. **Save / Re-evaluate buttons**: Same pattern as current ModelSelector — Save button (disabled when not dirty), Re-evaluate button (enabled after config change, triggers rescore). Place in a border-top separated action area.

7. **Warning for separate models**: Keep the memory warning from current ModelSelector.

**LLMProvidersSection.tsx** — Update to:
- Remove the temporary ModelSelector rendering (from Plan 02)
- Render `TopLevelModelSelector` as the FIRST section inside the "has providers" branch, inside a SettingsPanel with SettingsPanelHeading "Model Configuration"
- Pass it the same props: models, config, savedConfig, onConfigChange, onSave, isSaving

**Dead code cleanup** (do this as part of this task, after wiring is confirmed to compile):
- Delete `OllamaSection.tsx` (replaced by LLMProvidersSection)
- Delete or repurpose `ModelSelector.tsx` (replaced by TopLevelModelSelector)
- Remove `/settings/ollama/page.tsx` if it exists and is orphaned (or redirect to `/settings/llm-providers`)
- Remove `OllamaHealthBadge.tsx` if no longer imported anywhere (health is now on the pill)
- Clean up any unused imports across modified files
  </action>
  <verify>
    <automated>cd /Users/cstalhem/projects/worktrees/rss-reader/great-lehmann/frontend && bun run build 2>&1 | tail -20</automated>
    <manual>Navigate to /settings/llm-providers with Ollama configured. Verify Combobox shows models grouped under "Ollama" header. Type to search. Toggle separate models, verify two dropdowns appear. Save config change, verify save works.</manual>
  </verify>
  <done>TopLevelModelSelector renders a grouped searchable Combobox, supports separate-models toggle with mix-and-match, save/rescore flow works, integrated into LLMProvidersSection as top section, dead code removed</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Visual verification of complete LLM Providers page</name>
  <files>frontend/src/components/settings/LLMProvidersSection.tsx</files>
  <action>
Visual verification of the complete LLM Providers settings page redesign. Ensure all UI flows work end-to-end:
- Empty state with Add Provider button
- Provider pill bar with health indicator
- Add Provider dialog with Coming Soon badges
- Expandable Ollama provider panel (host/port, model library, disconnect)
- Top-level grouped searchable model selector
- System prompts at bottom
- Disconnect flow returning to empty state
  </action>
  <verify>
    <automated>cd /Users/cstalhem/projects/worktrees/rss-reader/great-lehmann/frontend && bun run build 2>&1 | tail -5</automated>
    <manual>
1. Navigate to /settings/llm-providers
2. If Ollama was previously configured: verify pill bar shows Ollama pill with health indicator
3. Click Ollama pill -- verify panel expands showing host/port fields, model library, disconnect button
4. Click pill again -- verify panel collapses (toggle behavior)
5. Click "Add Provider" -- verify dialog shows 5 provider cards with logos
6. Verify OpenAI/Anthropic/Google/OpenRouter cards show "Coming soon" badge and are not clickable
7. Close dialog, click the model selector Combobox at the top
8. Verify models are grouped under "Ollama" header, type to filter
9. Toggle "Use separate models" -- verify two Comboboxes appear
10. Change a model, verify Save button enables
11. Save config -- verify toast appears
12. Click "Disconnect Ollama" -- verify pill disappears, empty state shows
13. Click "Add Provider" from empty state, add Ollama back -- verify pill appears and panel auto-expands
14. Verify system prompts section is visible at the bottom
15. Verify no console errors
    </manual>
  </verify>
  <done>User has verified the complete LLM Providers page works correctly across all flows: empty state, add provider, configure, model selection, disconnect</done>
</task>

</tasks>

<verification>
1. `bun run build` passes
2. `bun run lint` passes
3. No dead imports or unused files remain from the refactor
4. Full add/configure/disconnect lifecycle verified visually
5. Model selector search, grouping, and save flow work end-to-end
</verification>

<success_criteria>
- Grouped searchable Combobox replaces Select dropdowns for model selection
- Models grouped by provider name in dropdown
- Separate-models toggle works with mix-and-match capability
- Save and Re-evaluate flow works from top-level selector
- Dead code from old OllamaSection/ModelSelector cleaned up
- Complete page verified visually by user
</success_criteria>

<output>
After completion, create `.planning/phases/09.6-llm-providers-settings-refresh/09.6-03-SUMMARY.md`
</output>
