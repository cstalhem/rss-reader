---
phase: 09.6-llm-providers-settings-refresh
plan: 03
type: execute
wave: 3
depends_on: ["09.6-02"]
files_modified:
  - frontend/src/components/settings/TopLevelModelSelector.tsx
  - frontend/src/components/settings/LLMProvidersSection.tsx
  - frontend/src/components/settings/ModelSelector.tsx
  - frontend/src/components/settings/OllamaSection.tsx
  - frontend/src/components/settings/OllamaHealthBadge.tsx
  - frontend/src/app/settings/ollama/page.tsx
autonomous: false
requirements:
  - OLLAMA-02
  - OLLAMA-05

must_haves:
  truths:
    - "User can search for models by name across all active providers via a grouped searchable dropdown"
    - "Model selector shows models grouped by provider name (e.g., 'Ollama' group header)"
    - "Separate-models toggle allows mix-and-match: different providers for categorization vs scoring"
    - "Save and Re-evaluate buttons work from the top-level model selector"
    - "TopLevelModelSelector uses useModelAssignments + useAvailableModels -- zero dependency on useOllamaConfig, useOllamaModels, or any provider-specific hook"
    - "Old OllamaSection.tsx and ModelSelector.tsx are deleted or repurposed (no dead code)"
    - "Old /settings/ollama route is removed or redirects to /settings/llm-providers"
  artifacts:
    - path: "frontend/src/components/settings/TopLevelModelSelector.tsx"
      provides: "Grouped Combobox model selector using useModelAssignments + useAvailableModels"
    - path: "frontend/src/components/settings/LLMProvidersSection.tsx"
      provides: "Updated orchestrator with TopLevelModelSelector at top"
  key_links:
    - from: "frontend/src/components/settings/TopLevelModelSelector.tsx"
      to: "frontend/src/hooks/useModelAssignments.ts"
      via: "reads task routes and saves model assignments"
      pattern: "useModelAssignments"
    - from: "frontend/src/components/settings/TopLevelModelSelector.tsx"
      to: "frontend/src/hooks/useAvailableModels.ts"
      via: "gets available models aggregated from all enabled providers"
      pattern: "useAvailableModels"
    - from: "frontend/src/components/settings/TopLevelModelSelector.tsx"
      to: "@chakra-ui/react"
      via: "Combobox with useListCollection and useFilter"
      pattern: "Combobox|useListCollection|useFilter"
    - from: "frontend/src/components/settings/LLMProvidersSection.tsx"
      to: "frontend/src/components/settings/TopLevelModelSelector.tsx"
      via: "renders TopLevelModelSelector above provider pills"
      pattern: "TopLevelModelSelector"
---

<objective>
Replace the temporary model selector with a top-level grouped searchable Combobox that reads/writes model assignments via useModelAssignments and gets available models via useAvailableModels (both provider-agnostic). Clean up dead code and verify the full page visually.

Key design decision: The model selector's data dependencies are useModelAssignments (task routes) and useAvailableModels (aggregated models from GET /api/models). It has zero dependency on any provider's config state or provider-specific hooks.

Purpose: The model selector is the primary user interaction on this page -- selecting which models to use for categorization and scoring across all providers.
Output: Working grouped model selector with search, complete page flow verified, dead code removed.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09.6-llm-providers-settings-refresh/09.6-CONTEXT.md
@.planning/phases/09.6-llm-providers-settings-refresh/09.6-RESEARCH.md
@.planning/phases/09.6-llm-providers-settings-refresh/09.6-01-SUMMARY.md
@.planning/phases/09.6-llm-providers-settings-refresh/09.6-02-SUMMARY.md

@frontend/src/components/settings/LLMProvidersSection.tsx
@frontend/src/components/settings/ModelSelector.tsx
@frontend/src/components/settings/OllamaSection.tsx
@frontend/src/components/settings/providers/registry.ts
@frontend/src/components/settings/providers/types.ts
@frontend/src/hooks/useModelAssignments.ts
@frontend/src/hooks/useAvailableModels.ts
@frontend/src/hooks/useScoringStatus.ts
@frontend/src/lib/types.ts
@frontend/src/lib/utils.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: TopLevelModelSelector with grouped Combobox</name>
  <files>
    frontend/src/components/settings/TopLevelModelSelector.tsx
    frontend/src/components/settings/LLMProvidersSection.tsx
  </files>
  <action>
**TopLevelModelSelector.tsx** -- New file. Replaces the old ModelSelector as the top-level model selection UI. This component is provider-agnostic in its data flow.

Internal hook calls:
```typescript
const { taskRoutes, useSeparateModels, saveMutation, rescoreMutation } = useModelAssignments();
const { models } = useAvailableModels(); // Aggregated from all enabled providers via GET /api/models
```

No props needed -- it's fully self-contained (same pattern as OllamaProviderPanel).

Uses Chakra Combobox with `useListCollection` and `useFilter` per research patterns.

Implementation:

1. **Build model items** for the collection: Map `AvailableModel[]` to `{ label: "modelname -- size (loaded)", value: "provider:modelname", provider: "ProviderLabel" }`. The value is prefixed with provider ID for uniqueness when multiple providers exist. Look up the provider's display label from `PROVIDER_REGISTRY` (e.g., `"ollama"` → `"Ollama"`). The `AvailableModel` type already carries the `provider` field from the backend.

2. **Extract a `ModelCombobox` sub-component**: Each Combobox instance needs its own `useFilter`, `useListCollection`, and `set()` sync — search/filter state is per-instance (typing in one Combobox must not affect the other). Extract this into a self-contained `ModelCombobox` component:

   ```tsx
   interface ModelComboboxProps {
     models: AvailableModel[];
     value: string | null;
     onChange: (provider: string, model: string) => void;
     label: string;
     disabled?: boolean;
   }
   ```

   Internally, `ModelCombobox` owns:
   - `useFilter({ sensitivity: "base" })` for search
   - `useListCollection({ initialItems, filter, groupBy })` for the grouped collection
   - `useEffect` to sync items via `set()` when `models` prop changes (reactivity: `initialItems` is NOT reactive — verified from Ark UI source, it passes to `useState` so only read on mount. The `set` function is stable, wrapped in Ark's `useEvent`.)
   - Combobox rendering: `Portal > Positioner > Content` (Combobox follows Select portal rules, not Dialog). Render `collection.group()` for grouped display with `Combobox.ItemGroup` and `Combobox.ItemGroupLabel`.
   - On selection: use `collection.find(selectedValue)` to get structured `{ provider, model }` from the item — never parse the value string. Call `onChange(item.provider, item.model)`.

   Define this as a private component in the same file as `TopLevelModelSelector` — it's not reused elsewhere.

3. **Separate models toggle**: `Switch.Root` for `use_separate_models` (from `useModelAssignments`). `TopLevelModelSelector` renders one or two `ModelCombobox` instances:
   - **Single mode** (toggle off): One `ModelCombobox` labeled "Model"
   - **Separate mode** (toggle on): Two `ModelCombobox` instances side by side in a responsive Grid — "Categorization" and "Scoring"

   Mix-and-match allowed per CONTEXT.md — different Comboboxes can select from different provider groups. Each instance has independent search state.

5. **Value mapping**: Task routes store `provider` + `model` separately. The Combobox value is an opaque string key — never parsed.
   - Build each item with structured fields: `{ value: "${provider}:${model}", provider: "ollama", model: "qwen3:4b", label: "..." }`
   - The `value` string is just a unique identifier for the collection's internal index — format doesn't matter
   - On selection, use `collection.find(selectedValue)` to get the full item object with `.provider` and `.model` fields — no string splitting
   - On render, convert task route to Combobox value: `${route.provider}:${route.model}` (matches the item's `value` key)

6. **Save / Re-evaluate buttons**: Save calls `saveMutation.mutate()` with the current local selections. Re-evaluate calls `rescoreMutation.mutate()`. Place in a border-top separated action area. Save disabled when selections match the server state.

7. **Local editing state**: `useState` for selected categorization and scoring values, synced from server data via `useEffect`:
   ```tsx
   const { taskRoutes } = useModelAssignments();
   const [localCat, setLocalCat] = useState<string | null>(null);
   const [localScore, setLocalScore] = useState<string | null>(null);

   useEffect(() => {
     if (taskRoutes) {
       setLocalCat(catValueFromRoutes(taskRoutes));
       setLocalScore(scoreValueFromRoutes(taskRoutes));
     }
   }, [taskRoutes]);
   ```
   This fires on initial load and after save (cache invalidation returns fresh data) — both are the right time to reset local state. No overlay/diff pattern needed: this is a single-user app, so concurrent edits and background refetches can't conflict with user interaction. If a selected model becomes unavailable before save, the backend rejects the `PUT /api/task-routes` and the MutationCache error handler shows a toast. Dirty detection: compare local values with server values.

8. **Warning for separate models**: Keep the memory warning from current ModelSelector.

**LLMProvidersSection.tsx** -- Update to:
- Remove the temporary ModelSelector rendering (from Plan 02)
- Render `TopLevelModelSelector` as the FIRST section inside the "has providers" branch, inside a SettingsPanel with SettingsPanelHeading "Model Configuration"
- No props to pass -- TopLevelModelSelector is self-contained

**Dead code cleanup** (do this after wiring is confirmed to compile):
- Delete `OllamaSection.tsx` (replaced by LLMProvidersSection)
- Delete or repurpose `ModelSelector.tsx` (replaced by TopLevelModelSelector)
- Remove `/settings/ollama/page.tsx` if it exists and is orphaned (or redirect to `/settings/llm-providers`)
- Remove `OllamaHealthBadge.tsx` if no longer imported anywhere (health is now in OllamaProviderPanel)
- Clean up any unused imports across modified files
  </action>
  <verify>
    <automated>cd /Users/cstalhem/projects/worktrees/rss-reader/great-lehmann/frontend && bun run build 2>&1 | tail -20</automated>
    <manual>Navigate to /settings/llm-providers with Ollama configured. Verify Combobox shows models grouped under "Ollama" header. Type to search. Toggle separate models, verify two dropdowns appear. Save config change, verify save works.</manual>
  </verify>
  <done>TopLevelModelSelector renders a grouped searchable Combobox using useModelAssignments + useAvailableModels (zero provider-specific dependency), supports separate-models toggle with mix-and-match, save/rescore flow works, integrated into LLMProvidersSection, dead code removed</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Visual verification of complete LLM Providers page</name>
  <files>frontend/src/components/settings/LLMProvidersSection.tsx</files>
  <action>
Visual verification of the complete LLM Providers settings page redesign. Ensure all UI flows work end-to-end:
- Empty state with Add Provider button
- Provider pill bar with toggle behavior
- Add Provider dialog with Coming Soon badges
- Expandable Ollama provider panel (host/port, health, model library, save, disconnect)
- Top-level grouped searchable model selector (independent from provider config)
- System prompts at bottom
- Disconnect flow returning to empty state
  </action>
  <verify>
    <automated>cd /Users/cstalhem/projects/worktrees/rss-reader/great-lehmann/frontend && bun run build 2>&1 | tail -5</automated>
    <manual>
1. Navigate to /settings/llm-providers
2. If Ollama was previously configured: verify pill bar shows Ollama pill
3. Click Ollama pill -- verify panel expands showing host/port fields, health status, model library, save button, disconnect button
4. Click pill again -- verify panel collapses (toggle behavior)
5. Click "Add Provider" -- verify dialog shows 5 provider cards with logos
6. Verify OpenAI/Anthropic/Google/OpenRouter cards show "Coming soon" badge and are not clickable
7. Close dialog, click the model selector Combobox at the top
8. Verify models are grouped under "Ollama" header, type to filter
9. Toggle "Use separate models" -- verify two Comboboxes appear
10. Change a model, verify Save button enables
11. Save model assignment -- verify toast appears
12. Verify provider panel save (host/port) works independently from model selector save
13. Click "Disconnect Ollama" -- verify ConfirmDialog warns about model assignments, confirm, verify pill disappears and empty state shows
14. Click "Add Provider" from empty state, add Ollama back -- verify pill appears and panel auto-expands
15. Verify system prompts section is visible at the bottom
16. Verify no console errors
    </manual>
  </verify>
  <done>User has verified the complete LLM Providers page works correctly across all flows: empty state, add provider, configure, model selection (independent), provider config (independent), disconnect</done>
</task>

</tasks>

<verification>
1. `bun run build` passes
2. `bun run lint` passes
3. No dead imports or unused files remain from the refactor
4. Full add/configure/disconnect lifecycle verified visually
5. Model selector uses useModelAssignments + useAvailableModels -- zero dependency on useOllamaConfig or useOllamaModels
6. Provider panel saves host/port independently from model selector
7. Model selector search, grouping, and save flow work end-to-end
</verification>

<success_criteria>
- Grouped searchable Combobox replaces Select dropdowns for model selection
- Models grouped by provider name in dropdown
- Separate-models toggle works with mix-and-match capability
- Model selector reads/writes via useModelAssignments (task routes) and useAvailableModels (aggregated models), not provider-specific hooks
- Save and Re-evaluate flow works from top-level selector
- Provider config save (host/port) is independent from model assignment save
- Dead code from old OllamaSection/ModelSelector cleaned up
- Complete page verified visually by user
</success_criteria>

<output>
After completion, create `.planning/phases/09.6-llm-providers-settings-refresh/09.6-03-SUMMARY.md`
</output>
