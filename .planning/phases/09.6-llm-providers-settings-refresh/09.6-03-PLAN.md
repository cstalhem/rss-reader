---
phase: 09.6-llm-providers-settings-refresh
plan: 03
type: execute
wave: 3
depends_on: ["09.6-02"]
files_modified:
  - frontend/src/components/settings/TopLevelModelSelector.tsx
  - frontend/src/components/settings/LLMProvidersSection.tsx
  - frontend/src/components/settings/ModelSelector.tsx
  - frontend/src/components/settings/OllamaSection.tsx
  - frontend/src/components/settings/OllamaHealthBadge.tsx
  - frontend/src/app/settings/ollama/page.tsx
autonomous: false
requirements:
  - OLLAMA-02
  - OLLAMA-05

must_haves:
  truths:
    - "User can search for models by name across all active providers via a grouped searchable dropdown"
    - "Model selector shows models grouped by provider name (e.g., 'Ollama' group header)"
    - "Separate-models toggle allows mix-and-match: different providers for categorization vs scoring"
    - "Save and Re-evaluate buttons work from the top-level model selector"
    - "TopLevelModelSelector uses useModelAssignments -- zero dependency on useOllamaConfig or any provider-specific hook"
    - "Old OllamaSection.tsx and ModelSelector.tsx are deleted or repurposed (no dead code)"
    - "Old /settings/ollama route is removed or redirects to /settings/llm-providers"
  artifacts:
    - path: "frontend/src/components/settings/TopLevelModelSelector.tsx"
      provides: "Grouped Combobox model selector using useModelAssignments"
    - path: "frontend/src/components/settings/LLMProvidersSection.tsx"
      provides: "Updated orchestrator with TopLevelModelSelector at top"
  key_links:
    - from: "frontend/src/components/settings/TopLevelModelSelector.tsx"
      to: "frontend/src/hooks/useModelAssignments.ts"
      via: "reads task routes and saves model assignments"
      pattern: "useModelAssignments"
    - from: "frontend/src/components/settings/TopLevelModelSelector.tsx"
      to: "frontend/src/hooks/useOllamaModels.ts"
      via: "gets available models (future: aggregate from all providers)"
      pattern: "useOllamaModels"
    - from: "frontend/src/components/settings/TopLevelModelSelector.tsx"
      to: "@chakra-ui/react"
      via: "Combobox with useListCollection and useFilter"
      pattern: "Combobox|useListCollection|useFilter"
    - from: "frontend/src/components/settings/LLMProvidersSection.tsx"
      to: "frontend/src/components/settings/TopLevelModelSelector.tsx"
      via: "renders TopLevelModelSelector above provider pills"
      pattern: "TopLevelModelSelector"
---

<objective>
Replace the temporary model selector with a top-level grouped searchable Combobox that reads/writes model assignments via useModelAssignments (independent of provider config). Clean up dead code and verify the full page visually.

Key design decision: The model selector's sole data dependency is useModelAssignments (task routes). It gets available models from useOllamaModels (future: aggregate from all providers). It has zero dependency on any provider's config state.

Purpose: The model selector is the primary user interaction on this page -- selecting which models to use for categorization and scoring across all providers.
Output: Working grouped model selector with search, complete page flow verified, dead code removed.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09.6-llm-providers-settings-refresh/09.6-CONTEXT.md
@.planning/phases/09.6-llm-providers-settings-refresh/09.6-RESEARCH.md
@.planning/phases/09.6-llm-providers-settings-refresh/09.6-01-SUMMARY.md
@.planning/phases/09.6-llm-providers-settings-refresh/09.6-02-SUMMARY.md

@frontend/src/components/settings/LLMProvidersSection.tsx
@frontend/src/components/settings/ModelSelector.tsx
@frontend/src/components/settings/OllamaSection.tsx
@frontend/src/components/settings/providers/registry.ts
@frontend/src/components/settings/providers/types.ts
@frontend/src/hooks/useModelAssignments.ts
@frontend/src/hooks/useOllamaModels.ts
@frontend/src/hooks/useScoringStatus.ts
@frontend/src/lib/types.ts
@frontend/src/lib/utils.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: TopLevelModelSelector with grouped Combobox</name>
  <files>
    frontend/src/components/settings/TopLevelModelSelector.tsx
    frontend/src/components/settings/LLMProvidersSection.tsx
  </files>
  <action>
**TopLevelModelSelector.tsx** -- New file. Replaces the old ModelSelector as the top-level model selection UI. This component is provider-agnostic in its data flow.

Internal hook calls:
```typescript
const { taskRoutes, useSeparateModels, saveMutation, rescoreMutation } = useModelAssignments();
const { models } = useOllamaModels(); // Future: aggregate from all active providers
```

No props needed -- it's fully self-contained (same pattern as OllamaProviderPanel).

Uses Chakra Combobox with `useListCollection` and `useFilter` per research patterns.

Implementation:

1. **Build model items** for the collection: Map models to `{ label: "modelname -- size (loaded)", value: "ollama:modelname", provider: "Ollama" }`. The value is prefixed with provider ID for uniqueness when multiple providers exist. Currently only Ollama models, but the structure supports future providers.

2. **useFilter + useListCollection**: Per research pattern:
   ```tsx
   const { contains } = useFilter({ sensitivity: "base" });
   const { collection, filter } = useListCollection({
     initialItems: modelItems,
     filter: contains,
     groupBy: (item) => item.provider,
   });
   ```

   **Reactivity note from research:** `useListCollection` uses `initialItems`. If models change (download/delete), the collection may not update. Handle this by passing a `key` prop on the Combobox parent keyed on `models.length` (or a hash) to force remount when models change. Test this during implementation -- if `useListCollection` IS reactive to `initialItems` reference changes, the key prop is unnecessary.

3. **Combobox rendering**: Per research code example. Use `Portal > Positioner > Content` (Combobox follows Select portal rules, not Dialog). Render `collection.group()` for grouped display with `Combobox.ItemGroup` and `Combobox.ItemGroupLabel`.

4. **Separate models toggle**: `Switch.Root` for `use_separate_models` (from `useModelAssignments`). When enabled, show two Comboboxes side by side (categorization + scoring) in a responsive Grid. When disabled, show one Combobox labeled "Model". Mix-and-match allowed per CONTEXT.md -- different Comboboxes can select from different provider groups.

5. **Value mapping**: Task routes store `provider` + `model` separately. The Combobox values use `provider:model` format:
   - Convert task route to Combobox value on render: `${route.provider}:${route.model}`
   - Convert Combobox value back on change: split on first `:` to get provider + model
   - Handle missing model (model deleted while assigned): include it as a "missing" item with warning indicator

6. **Save / Re-evaluate buttons**: Save calls `saveMutation.mutate()` with the current local selections. Re-evaluate calls `rescoreMutation.mutate()`. Place in a border-top separated action area. Save disabled when selections match the server state.

7. **Local editing state**: Simple `useState` for the selected categorization and scoring values. Initialize from `taskRoutes` on load. Dirty detection: compare local values with server values.

8. **Warning for separate models**: Keep the memory warning from current ModelSelector.

**LLMProvidersSection.tsx** -- Update to:
- Remove the temporary ModelSelector rendering (from Plan 02)
- Render `TopLevelModelSelector` as the FIRST section inside the "has providers" branch, inside a SettingsPanel with SettingsPanelHeading "Model Configuration"
- No props to pass -- TopLevelModelSelector is self-contained

**Dead code cleanup** (do this after wiring is confirmed to compile):
- Delete `OllamaSection.tsx` (replaced by LLMProvidersSection)
- Delete or repurpose `ModelSelector.tsx` (replaced by TopLevelModelSelector)
- Remove `/settings/ollama/page.tsx` if it exists and is orphaned (or redirect to `/settings/llm-providers`)
- Remove `OllamaHealthBadge.tsx` if no longer imported anywhere (health is now in OllamaProviderPanel)
- Clean up any unused imports across modified files
  </action>
  <verify>
    <automated>cd /Users/cstalhem/projects/worktrees/rss-reader/great-lehmann/frontend && bun run build 2>&1 | tail -20</automated>
    <manual>Navigate to /settings/llm-providers with Ollama configured. Verify Combobox shows models grouped under "Ollama" header. Type to search. Toggle separate models, verify two dropdowns appear. Save config change, verify save works.</manual>
  </verify>
  <done>TopLevelModelSelector renders a grouped searchable Combobox using useModelAssignments (zero provider-config dependency), supports separate-models toggle with mix-and-match, save/rescore flow works, integrated into LLMProvidersSection, dead code removed</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Visual verification of complete LLM Providers page</name>
  <files>frontend/src/components/settings/LLMProvidersSection.tsx</files>
  <action>
Visual verification of the complete LLM Providers settings page redesign. Ensure all UI flows work end-to-end:
- Empty state with Add Provider button
- Provider pill bar with toggle behavior
- Add Provider dialog with Coming Soon badges
- Expandable Ollama provider panel (host/port, health, model library, save, disconnect)
- Top-level grouped searchable model selector (independent from provider config)
- System prompts at bottom
- Disconnect flow returning to empty state
  </action>
  <verify>
    <automated>cd /Users/cstalhem/projects/worktrees/rss-reader/great-lehmann/frontend && bun run build 2>&1 | tail -5</automated>
    <manual>
1. Navigate to /settings/llm-providers
2. If Ollama was previously configured: verify pill bar shows Ollama pill
3. Click Ollama pill -- verify panel expands showing host/port fields, health status, model library, save button, disconnect button
4. Click pill again -- verify panel collapses (toggle behavior)
5. Click "Add Provider" -- verify dialog shows 5 provider cards with logos
6. Verify OpenAI/Anthropic/Google/OpenRouter cards show "Coming soon" badge and are not clickable
7. Close dialog, click the model selector Combobox at the top
8. Verify models are grouped under "Ollama" header, type to filter
9. Toggle "Use separate models" -- verify two Comboboxes appear
10. Change a model, verify Save button enables
11. Save model assignment -- verify toast appears
12. Verify provider panel save (host/port) works independently from model selector save
13. Click "Disconnect Ollama" -- verify ConfirmDialog warns about model assignments, confirm, verify pill disappears and empty state shows
14. Click "Add Provider" from empty state, add Ollama back -- verify pill appears and panel auto-expands
15. Verify system prompts section is visible at the bottom
16. Verify no console errors
    </manual>
  </verify>
  <done>User has verified the complete LLM Providers page works correctly across all flows: empty state, add provider, configure, model selection (independent), provider config (independent), disconnect</done>
</task>

</tasks>

<verification>
1. `bun run build` passes
2. `bun run lint` passes
3. No dead imports or unused files remain from the refactor
4. Full add/configure/disconnect lifecycle verified visually
5. Model selector uses useModelAssignments -- zero dependency on useOllamaConfig
6. Provider panel saves host/port independently from model selector
7. Model selector search, grouping, and save flow work end-to-end
</verification>

<success_criteria>
- Grouped searchable Combobox replaces Select dropdowns for model selection
- Models grouped by provider name in dropdown
- Separate-models toggle works with mix-and-match capability
- Model selector reads/writes via useModelAssignments (task routes), not provider config
- Save and Re-evaluate flow works from top-level selector
- Provider config save (host/port) is independent from model assignment save
- Dead code from old OllamaSection/ModelSelector cleaned up
- Complete page verified visually by user
</success_criteria>

<output>
After completion, create `.planning/phases/09.6-llm-providers-settings-refresh/09.6-03-SUMMARY.md`
</output>
