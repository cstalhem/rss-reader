---
phase: 09.6-llm-providers-settings-refresh
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/src/backend/routers/ollama.py
  - backend/src/backend/schemas.py
  - frontend/src/lib/types.ts
  - frontend/src/lib/api.ts
  - frontend/src/lib/queryKeys.ts
  - frontend/src/hooks/useProviders.ts
  - frontend/src/hooks/useModelAssignments.ts
  - frontend/src/components/settings/providers/types.ts
  - frontend/src/components/settings/providers/registry.ts
  - frontend/src/components/settings/providers/ollama/index.ts
  - frontend/src/components/settings/providers/ollama/OllamaLogo.tsx
  - frontend/src/components/settings/providers/openai/index.ts
  - frontend/src/components/settings/providers/openai/OpenAILogo.tsx
  - frontend/src/components/settings/providers/anthropic/index.ts
  - frontend/src/components/settings/providers/anthropic/AnthropicLogo.tsx
  - frontend/src/components/settings/providers/google/index.ts
  - frontend/src/components/settings/providers/google/GoogleLogo.tsx
  - frontend/src/components/settings/providers/openrouter/index.ts
  - frontend/src/components/settings/providers/openrouter/OpenRouterLogo.tsx
autonomous: true
requirements:
  - OLLAMA-01
  - OLLAMA-02

must_haves:
  truths:
    - "GET /api/providers returns the list of configured providers with enabled status"
    - "PATCH /api/providers/{provider}/disconnect sets enabled=false and clears task routes"
    - "PUT /api/providers/{provider}/config saves provider-specific config (replaces PUT /api/ollama/config)"
    - "Backend endpoints have TODO comments noting extraction to a dedicated providers router when a second provider is added"
    - "GET /api/task-routes returns current model assignments (task, provider, model)"
    - "PUT /api/task-routes saves model assignments independently from provider config"
    - "Frontend useProviders hook fetches provider list and exposes disconnect mutation"
    - "Frontend useModelAssignments hook reads/writes task routes independently from provider config"
    - "ProviderPlugin interface defines the contract for all provider modules"
    - "PROVIDER_REGISTRY lists all 5 providers with availability flags, logos, and panel references"
    - "Each provider has a self-contained module directory under providers/"
    - "SVG logo components exist for all 5 providers using user-sourced brand marks"
  artifacts:
    - path: "backend/src/backend/routers/ollama.py"
      provides: "Provider endpoints (list, disconnect, config) and task-route endpoints (with extraction TODO)"
    - path: "frontend/src/hooks/useProviders.ts"
      provides: "useProviders hook with query + disconnect mutation"
    - path: "frontend/src/hooks/useModelAssignments.ts"
      provides: "useModelAssignments hook â€” reads/writes task routes, triggers rescore"
    - path: "frontend/src/components/settings/providers/types.ts"
      provides: "ProviderPlugin interface and ProviderPanelProps type"
    - path: "frontend/src/components/settings/providers/registry.ts"
      provides: "PROVIDER_REGISTRY array"
    - path: "frontend/src/components/settings/providers/ollama/index.ts"
      provides: "Ollama provider plugin module export"
  key_links:
    - from: "frontend/src/hooks/useProviders.ts"
      to: "/api/providers"
      via: "fetchProviders API function"
      pattern: "fetch.*api/providers"
    - from: "frontend/src/hooks/useModelAssignments.ts"
      to: "/api/task-routes"
      via: "fetchTaskRoutes and saveTaskRoutes API functions"
      pattern: "task.routes"
    - from: "frontend/src/components/settings/providers/registry.ts"
      to: "frontend/src/components/settings/providers/*/index.ts"
      via: "imports each provider's plugin export"
      pattern: "PROVIDER_REGISTRY"
---

<objective>
Build the data layer foundation for the multi-provider LLM settings page: backend endpoints for providers, provider config, and model assignments (all separated), frontend provider plugin module structure mirroring the backend's llm_providers/ pattern, API client, TanStack Query hooks, and per-provider logo components.

Key design decisions:
- Model assignments (which model for categorization/scoring) are a cross-provider concern, decoupled from per-provider config (host/port). The backend already has this separation (LLMProviderConfig vs LLMTaskRoute); this plan brings the frontend in line.
- Provider config uses a provider-agnostic URL pattern: PUT /api/providers/{provider}/config (replaces the old PUT /api/ollama/config).

Purpose: All subsequent plans need provider data and model assignment data flowing independently. This is the shared foundation.
Output: Working backend endpoints, typed frontend data layer, provider plugin modules with logos, model assignments hook, ready for UI consumption.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09.6-llm-providers-settings-refresh/09.6-CONTEXT.md
@.planning/phases/09.6-llm-providers-settings-refresh/09.6-RESEARCH.md

@backend/src/backend/routers/ollama.py
@backend/src/backend/schemas.py
@backend/src/backend/deps.py
@backend/src/backend/models.py
@backend/src/backend/llm_providers/base.py
@backend/src/backend/llm_providers/registry.py
@frontend/src/lib/types.ts
@frontend/src/lib/api.ts
@frontend/src/lib/queryKeys.ts
@frontend/src/hooks/useOllamaConfig.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Backend provider, config, and task-route endpoints</name>
  <files>
    backend/src/backend/routers/ollama.py
    backend/src/backend/schemas.py
  </files>
  <action>
Add new endpoints to the ollama router with clear TODO comments about future extraction:

```python
# TODO: Extract provider, config, and task-route endpoints to dedicated routers
# (e.g., routers/providers.py, routers/task_routes.py) when adding a
# second provider implementation. These live here temporarily because
# Ollama is the only active provider.
```

**Provider endpoints:**

1. **GET /api/providers** -- Query `LLMProviderConfig` table, return list of `{provider: string, enabled: bool}`. If no rows exist, return an empty list.

2. **PATCH /api/providers/{provider}/disconnect** -- Find the `LLMProviderConfig` row for the given provider name. Set `enabled = False`. Also clear any `LLMTaskRoute` rows referencing this provider (delete them or set provider/model to empty) so the scoring pipeline doesn't try to use a disconnected provider. Return `{ok: true}`. If provider not found, return 404.

Per research decision: "disconnect" sets `enabled: false` rather than deleting the row, preserving host/port config for easy reconnect.

**Provider config endpoint:**

3. **PUT /api/providers/{provider}/config** -- Provider-agnostic URL that replaces the old `PUT /api/ollama/config`. Dispatch based on provider name:
   - For `"ollama"`: same logic as the existing `PUT /api/ollama/config` (validate OllamaProviderConfig, upsert LLMProviderConfig row with `enabled=True`, sync task routes via `sync_ollama_task_routes`).
   - For unknown providers: return 404.
   - Keep the old `PUT /api/ollama/config` endpoint temporarily as a redirect or alias for backward compatibility (existing frontend code may still call it until Plan 02 updates the frontend). Mark it deprecated with a TODO.

This endpoint handles both initial creation (user adds provider and saves for the first time) and subsequent updates (user edits host/port). The upsert in `upsert_ollama_provider_config` already handles both cases -- verify it also re-enables `enabled=True` on existing rows that were previously disconnected.

**Task-route endpoints (model assignments):**

4. **GET /api/task-routes** -- Query `LLMTaskRoute` table. Return list of `{task: string, provider: string, model: string | null}`. The frontend needs this to populate the model selector independently from any provider's config. Also include `use_separate_models: bool` -- read this from the Ollama config's `use_separate_models` field for now (this flag is a UI preference, not truly Ollama-specific; a future refactor could move it to a dedicated UI preferences table, but that's out of scope).

5. **PUT /api/task-routes** -- Accept `{categorization: {provider: string, model: string}, scoring: {provider: string, model: string}, use_separate_models: bool}`. Upsert the two `LLMTaskRoute` rows using existing `upsert_task_route()`. Also save `use_separate_models` back to the active Ollama config (for now; same pragmatic placement as the GET). Return `{ok: true}`.

**Response schemas to add in `schemas.py`:**
- `ProviderListItem(provider: str, enabled: bool)`
- `TaskRouteItem(task: str, provider: str, model: str | None)`
- `TaskRoutesResponse(routes: list[TaskRouteItem], use_separate_models: bool)`
- `TaskRoutesUpdate(categorization: TaskRouteAssignment, scoring: TaskRouteAssignment, use_separate_models: bool)`
- `TaskRouteAssignment(provider: str, model: str)`
  </action>
  <verify>
    <automated>cd /Users/cstalhem/projects/worktrees/rss-reader/great-lehmann && uv run python -c "from backend.routers.ollama import router; routes = [r.path for r in router.routes]; print(routes); assert any('providers' in r for r in routes); assert any('task-routes' in r for r in routes); print('OK: all endpoints registered')"</automated>
    <manual>Check that GET /api/providers returns [] on cold start, PUT /api/providers/ollama/config creates a row, GET /api/task-routes returns current routes, PUT /api/task-routes updates model assignments</manual>
  </verify>
  <done>Provider endpoints (list, disconnect, config), task-route endpoints (get, save) all working. Provider config uses provider-agnostic URL pattern. Response schemas defined. TODO comments document extraction requirement.</done>
</task>

<task type="auto">
  <name>Task 2: Frontend provider plugin modules, data layer, and hooks</name>
  <files>
    frontend/src/lib/types.ts
    frontend/src/lib/api.ts
    frontend/src/lib/queryKeys.ts
    frontend/src/hooks/useProviders.ts
    frontend/src/hooks/useModelAssignments.ts
    frontend/src/components/settings/providers/types.ts
    frontend/src/components/settings/providers/registry.ts
    frontend/src/components/settings/providers/ollama/index.ts
    frontend/src/components/settings/providers/ollama/OllamaLogo.tsx
    frontend/src/components/settings/providers/openai/index.ts
    frontend/src/components/settings/providers/openai/OpenAILogo.tsx
    frontend/src/components/settings/providers/anthropic/index.ts
    frontend/src/components/settings/providers/anthropic/AnthropicLogo.tsx
    frontend/src/components/settings/providers/google/index.ts
    frontend/src/components/settings/providers/google/GoogleLogo.tsx
    frontend/src/components/settings/providers/openrouter/index.ts
    frontend/src/components/settings/providers/openrouter/OpenRouterLogo.tsx
  </files>
  <action>
This task mirrors the backend's `llm_providers/` plugin module pattern on the frontend. Each provider is a self-contained directory exporting a standard `ProviderPlugin` shape.

**1. Provider plugin interface** -- `providers/types.ts`:
```typescript
import type { ComponentType, SVGProps } from "react";

export interface ProviderPanelProps {
  onDisconnect: () => void;
  isNew?: boolean;           // true = provider not yet saved to backend
  onCancelSetup?: () => void; // remove from pending list without saving
}

export interface ProviderPlugin {
  id: string;
  label: string;
  hint: string;
  available: boolean;
  Logo: ComponentType<SVGProps<SVGSVGElement>>;
  Panel: ComponentType<ProviderPanelProps> | null; // null = not yet implemented
}
```

Note: `ProviderPanelProps` is intentionally minimal. Each provider panel is self-contained -- it calls its own hooks internally (e.g., `useOllamaConfig`, `useOllamaHealth`, `useOllamaModels`) rather than receiving data via props. The orchestrator only passes the base contract. This is possible because model assignments are decoupled from provider config.

When `isNew` is true, the panel initializes with defaults instead of fetching from the server, and shows Save + Cancel buttons instead of Disconnect.

**2. Per-provider module directories** -- Create one directory per provider under `providers/`:

Each provider directory contains:
- `{Provider}Logo.tsx` -- Inline SVG component with `fill="currentColor"`, `viewBox="0 0 24 24"`, `width="1em"`, `height="1em"`. SVG path data is user-sourced. Create the React component wrapper with a placeholder `<circle cx="12" cy="12" r="10" />` and a comment: `// TODO: Replace placeholder with actual brand SVG path data`.
- `index.ts` -- Exports the `ProviderPlugin` object.

Example for Ollama:
```typescript
// providers/ollama/index.ts
import type { ProviderPlugin } from "../types";
import { OllamaLogo } from "./OllamaLogo";

export const ollamaProvider: ProviderPlugin = {
  id: "ollama",
  label: "Ollama",
  hint: "Local -- no API key",
  available: true,
  Logo: OllamaLogo,
  Panel: null, // Created in Plan 02
};
```

For the 4 "coming soon" providers (OpenAI, Anthropic, Google, OpenRouter):
- `available: false`
- `Panel: null`
- Same Logo component structure with placeholder SVG

**3. Provider registry** -- `providers/registry.ts`:
```typescript
import { ollamaProvider } from "./ollama";
import { openaiProvider } from "./openai";
import { anthropicProvider } from "./anthropic";
import { googleProvider } from "./google";
import { openrouterProvider } from "./openrouter";
import type { ProviderPlugin } from "./types";

export const PROVIDER_REGISTRY: ProviderPlugin[] = [
  ollamaProvider,
  openaiProvider,
  anthropicProvider,
  googleProvider,
  openrouterProvider,
];
```

**4. API response types** -- `lib/types.ts`:
```typescript
export interface ProviderListItem {
  provider: string;
  enabled: boolean;
}

export interface TaskRouteItem {
  task: string;
  provider: string;
  model: string | null;
}

export interface TaskRoutesResponse {
  routes: TaskRouteItem[];
  use_separate_models: boolean;
}

export interface TaskRoutesUpdate {
  categorization: { provider: string; model: string };
  scoring: { provider: string; model: string };
  use_separate_models: boolean;
}
```

**5. API functions** -- `lib/api.ts`:
- `fetchProviders(): Promise<ProviderListItem[]>` -- GET /api/providers
- `disconnectProvider(provider: string): Promise<{ok: boolean}>` -- PATCH /api/providers/{provider}/disconnect
- `saveProviderConfig(provider: string, config: unknown): Promise<OllamaConfig>` -- PUT /api/providers/{provider}/config (returns saved config)
- `fetchTaskRoutes(): Promise<TaskRoutesResponse>` -- GET /api/task-routes
- `saveTaskRoutes(data: TaskRoutesUpdate): Promise<{ok: boolean}>` -- PUT /api/task-routes

**6. Query keys** -- `lib/queryKeys.ts`:
```typescript
providers: {
  all: ["providers"] as const,
},
taskRoutes: {
  all: ["task-routes"] as const,
},
```

**7. useProviders hook** -- `hooks/useProviders.ts`:
- `useQuery` with `queryKeys.providers.all` and `fetchProviders` as queryFn
- `useMutation` for disconnect with `meta: { errorTitle: "Failed to disconnect provider" }`, invalidates `queryKeys.providers.all` and `queryKeys.taskRoutes.all` on settled (disconnect clears task routes)
- Returns `{ providers, isLoading, disconnectMutation }`

**8. useModelAssignments hook** -- `hooks/useModelAssignments.ts`:
- `useQuery` with `queryKeys.taskRoutes.all` and `fetchTaskRoutes` as queryFn
- `useMutation` for save with `meta: { errorTitle: "Failed to save model assignments" }`, invalidates `queryKeys.taskRoutes.all` on success
- Separate `rescoreMutation` using existing `triggerRescore` from api.ts
- Returns `{ taskRoutes, useSeparateModels, isLoading, saveMutation, rescoreMutation }`

This hook is the model selector's sole data dependency. It knows nothing about Ollama config, host/port, or any provider-specific state.

**9. Update useOllamaConfig** -- Update `saveOllamaConfig` in `api.ts` to call `PUT /api/providers/ollama/config` instead of `PUT /api/ollama/config`. The hook itself stays the same -- it still manages Ollama-specific config (host/port). It just uses the new URL.
  </action>
  <verify>
    <automated>cd /Users/cstalhem/projects/worktrees/rss-reader/great-lehmann/frontend && bun run build 2>&1 | tail -20</automated>
    <manual>Verify providers/ directory structure exists with 5 provider modules, registry exports PROVIDER_REGISTRY with 5 entries, both hooks compile</manual>
  </verify>
  <done>Provider plugin module structure created mirroring backend pattern. ProviderPlugin interface with isNew/onCancelSetup support, 5 provider modules with Logo placeholders, PROVIDER_REGISTRY, data types, API functions (using new provider-agnostic URLs), useProviders hook, useModelAssignments hook, and query keys all compile without errors.</done>
</task>

</tasks>

<verification>
1. Backend: `uv run ruff check backend/src/backend/routers/ollama.py backend/src/backend/schemas.py` passes
2. Frontend: `bun run build` succeeds with no type errors
3. Query keys: `queryKeys.providers.all` and `queryKeys.taskRoutes.all` exist
4. Registry: PROVIDER_REGISTRY has 5 entries with Ollama as `available: true`
5. Plugin structure: Each provider directory has index.ts + Logo component
6. TODO comments present on backend endpoints
7. useModelAssignments has no dependency on useOllamaConfig or any provider-specific hook
8. PUT /api/providers/{provider}/config endpoint works for Ollama
9. Old PUT /api/ollama/config marked deprecated
</verification>

<success_criteria>
- Backend serves provider endpoints (list, disconnect, config) and task-route endpoints
- Provider config uses provider-agnostic URL: PUT /api/providers/{provider}/config
- Provider plugin module structure mirrors backend llm_providers/ pattern
- ProviderPlugin interface defines the standard contract with isNew/onCancelSetup for setup flow
- 5 provider modules created with Logo placeholders (user will supply SVG path data)
- PROVIDER_REGISTRY replaces the flat PROVIDER_CATALOG concept
- useModelAssignments reads/writes task routes independently -- no provider config dependency
- useProviders manages provider list and disconnect
- No lint or type errors
</success_criteria>

<output>
After completion, create `.planning/phases/09.6-llm-providers-settings-refresh/09.6-01-SUMMARY.md`
</output>
