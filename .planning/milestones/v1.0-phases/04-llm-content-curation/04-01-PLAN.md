---
phase: 04-llm-content-curation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/src/backend/models.py
  - backend/src/backend/main.py
  - backend/src/backend/config.py
  - backend/src/backend/database.py
  - docker-compose.yml
  - frontend/src/lib/types.ts
  - frontend/src/lib/api.ts
autonomous: true

must_haves:
  truths:
    - "UserPreferences model exists with interests, anti_interests, and topic_weights fields"
    - "Article model has scoring fields (categories, interest_score, quality_score, composite_score, score_reasoning, scoring_state)"
    - "GET/PUT /api/preferences endpoints return and save user preferences"
    - "GET /api/categories returns list of known categories"
    - "Article list endpoint returns scoring fields in response"
    - "Ollama service defined in Docker Compose"
  artifacts:
    - path: "backend/src/backend/models.py"
      provides: "Article scoring fields + UserPreferences model"
      contains: "class UserPreferences"
    - path: "backend/src/backend/main.py"
      provides: "Preferences CRUD + categories endpoints"
      contains: "api/preferences"
    - path: "backend/src/backend/config.py"
      provides: "Ollama configuration section"
      contains: "class OllamaConfig"
    - path: "docker-compose.yml"
      provides: "Ollama service definition"
      contains: "ollama"
    - path: "frontend/src/lib/types.ts"
      provides: "Updated Article + new UserPreferences TypeScript types"
      contains: "scoring_state"
    - path: "frontend/src/lib/api.ts"
      provides: "fetchPreferences, updatePreferences, fetchCategories functions"
      contains: "api/preferences"
  key_links:
    - from: "backend/src/backend/main.py"
      to: "backend/src/backend/models.py"
      via: "import UserPreferences, Article with scoring fields"
      pattern: "from backend.models import.*UserPreferences"
    - from: "frontend/src/lib/api.ts"
      to: "/api/preferences"
      via: "fetch calls to preferences endpoints"
      pattern: "api/preferences"
---

<objective>
Create the backend data foundation for LLM content curation: extend Article model with scoring fields, create UserPreferences model, add CRUD endpoints for preferences and categories, update frontend types, and add Ollama service to Docker Compose.

Purpose: All subsequent plans (scoring engine, settings UI, article UI) depend on these models, endpoints, and types existing.
Output: Working API endpoints for preferences management, Article model ready for scoring data, Ollama available as Docker service.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-llm-content-curation/04-RESEARCH.md
@.planning/phases/04-llm-content-curation/04-CONTEXT.md
@backend/src/backend/models.py
@backend/src/backend/main.py
@backend/src/backend/config.py
@backend/src/backend/database.py
@docker-compose.yml
@frontend/src/lib/types.ts
@frontend/src/lib/api.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend data models and config for LLM scoring</name>
  <files>
    backend/src/backend/models.py
    backend/src/backend/config.py
    backend/src/backend/database.py
  </files>
  <action>
    In `models.py`, add scoring fields to the existing Article model:
    - `categories: list[str] | None = Field(default=None, sa_column=Column(JSON))` — LLM-assigned topic categories
    - `interest_score: int | None = Field(default=None)` — Base interest score 0-10
    - `quality_score: int | None = Field(default=None)` — Quality score 0-10
    - `composite_score: float | None = Field(default=None)` — Final weighted score
    - `score_reasoning: str | None = Field(default=None)` — LLM explanation
    - `scoring_state: str = Field(default="unscored")` — One of: unscored, queued, scoring, scored, failed
    - `scored_at: datetime | None = Field(default=None)` — When scoring completed

    Import `Column` from `sqlalchemy` and `JSON` from `sqlalchemy` at top of file. Add `model_config = {"arbitrary_types_allowed": True}` to Article class (SQLModel v2 style, not inner Config class — check which pattern works with current SQLModel version; if inner Config class is needed, use that).

    Create a new `UserPreferences` model (single-row table for this single-user app):
    - `id: int | None = Field(default=None, primary_key=True)`
    - `interests: str = Field(default="")` — Free-form interest prose
    - `anti_interests: str = Field(default="")` — Free-form anti-interest prose
    - `topic_weights: dict[str, str] | None = Field(default=None, sa_column=Column(JSON))` — Category name to weight mapping (blocked/low/neutral/medium/high)
    - `updated_at: datetime = Field(default_factory=datetime.now)`

    In `config.py`, add an `OllamaConfig` section to Settings:
    - `host: str = "http://localhost:11434"` — Ollama server URL
    - `categorization_model: str = "qwen2.5:7b"` — Model for step 1
    - `scoring_model: str = "qwen2.5:14b"` — Model for step 2
    - `timeout: float = 120.0` — Timeout in seconds for LLM calls

    Add `ollama: OllamaConfig = OllamaConfig()` to the Settings class.

    In `database.py`, ensure `create_db_and_tables()` will pick up the new model. The existing code uses `SQLModel.metadata.create_all(engine)` which auto-discovers imported models. Verify UserPreferences is imported in `main.py` (done in Task 2) so its table is created.
  </action>
  <verify>
    Run `cd /Users/cstalhem/projects/rss-reader/backend && uv run python -c "from backend.models import Article, UserPreferences; print('Models OK')"` to confirm imports work.
    Run `cd /Users/cstalhem/projects/rss-reader/backend && uv run ruff check src/` to confirm no lint errors.
  </verify>
  <done>
    Article model has 7 new scoring fields (categories, interest_score, quality_score, composite_score, score_reasoning, scoring_state, scored_at). UserPreferences model exists with interests, anti_interests, topic_weights, updated_at. OllamaConfig exists in settings with host, models, timeout.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create preferences and categories API endpoints</name>
  <files>
    backend/src/backend/main.py
    frontend/src/lib/types.ts
    frontend/src/lib/api.ts
  </files>
  <action>
    In `main.py`, add import for `UserPreferences` from models. Create Pydantic request/response models:
    - `PreferencesResponse(BaseModel)`: interests (str), anti_interests (str), topic_weights (dict[str, str] | None), updated_at (datetime)
    - `PreferencesUpdate(BaseModel)`: interests (str | None = None), anti_interests (str | None = None), topic_weights (dict[str, str] | None = None)

    Add these endpoints:

    **GET /api/preferences** — Return the single UserPreferences row. If none exists, create a default one with empty strings and return it.

    **PUT /api/preferences** — Update preferences. Merge non-None fields into existing row. Update `updated_at` to datetime.now(). Return updated preferences. This endpoint also needs to return a `rescore_triggered: bool` field indicating whether re-scoring was requested (always true on save — the actual re-scoring is wired in Plan 02).

    **GET /api/categories** — Return a sorted list of unique category strings from all articles that have been scored. Query all articles where `categories IS NOT NULL`, collect unique category names (normalized lowercase for comparison but preserve original case of first occurrence), return as `list[str]`. This gives the settings page the list of known categories for the weight editor.

    **PATCH /api/categories/{category_name}/weight** — Quick-update a single category's weight. Accepts body `{"weight": "blocked"|"low"|"neutral"|"medium"|"high"}`. Loads preferences, updates `topic_weights[category_name.lower()] = weight`, saves, returns updated preferences. This powers the quick-block/boost from article tag chips.

    In `frontend/src/lib/types.ts`, add:
    - Scoring fields to Article interface: categories (string[] | null), interest_score (number | null), quality_score (number | null), composite_score (number | null), score_reasoning (string | null), scoring_state (string), scored_at (string | null)
    - New `UserPreferences` interface: interests (string), anti_interests (string), topic_weights (Record<string, string> | null), updated_at (string)

    In `frontend/src/lib/api.ts`, add functions:
    - `fetchPreferences(): Promise<UserPreferences>` — GET /api/preferences
    - `updatePreferences(data: Partial<UserPreferences>): Promise<UserPreferences>` — PUT /api/preferences
    - `fetchCategories(): Promise<string[]>` — GET /api/categories
    - `updateCategoryWeight(category: string, weight: string): Promise<UserPreferences>` — PATCH /api/categories/{category}/weight
  </action>
  <verify>
    Run `cd /Users/cstalhem/projects/rss-reader/backend && uv run ruff check src/` for lint.
    Run `cd /Users/cstalhem/projects/rss-reader/backend && uv run pytest tests/ -x` to confirm existing tests still pass.
    Run `cd /Users/cstalhem/projects/rss-reader/frontend && npx tsc --noEmit` to confirm TypeScript compiles.
  </verify>
  <done>
    GET /api/preferences returns default preferences when none exist. PUT /api/preferences saves and returns updated preferences. GET /api/categories returns unique category list from scored articles. PATCH /api/categories/{name}/weight updates single category weight. Frontend types include all Article scoring fields and UserPreferences interface. Frontend api.ts has all four new functions.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add Ollama service to Docker Compose</name>
  <files>
    docker-compose.yml
  </files>
  <action>
    Add Ollama service to docker-compose.yml:

    ```yaml
    ollama:
      image: ollama/ollama:latest
      container_name: rss-reader-ollama
      restart: unless-stopped
      volumes:
        - ollama-data:/root/.ollama
      ports:
        - "11434:11434"
      networks:
        - rss-reader
    ```

    Add `ollama-data` to the volumes section alongside existing `db-data`.

    Update the backend service to add `OLLAMA__HOST=http://ollama:11434` to environment variables, so the backend can reach Ollama via the Docker network. Also add a dependency: `depends_on` should include `ollama` (no health check condition needed — the scoring queue handles Ollama being unavailable gracefully via retry).

    Note: Do NOT add a healthcheck for Ollama — it may take minutes to pull models on first start. The scoring queue in Plan 02 handles connection failures with retries.
  </action>
  <verify>
    Verify docker-compose.yml is valid YAML by running `cd /Users/cstalhem/projects/rss-reader && python3 -c "import yaml; yaml.safe_load(open('docker-compose.yml'))"` (or similar validation).
  </verify>
  <done>
    docker-compose.yml defines Ollama service with persistent volume, backend can reach Ollama at http://ollama:11434 via Docker network, backend environment has OLLAMA__HOST set.
  </done>
</task>

</tasks>

<verification>
- `uv run python -c "from backend.models import Article, UserPreferences; a = Article(feed_id=1, title='t', url='u'); print(a.scoring_state)"` prints "unscored"
- `uv run ruff check src/` passes
- `uv run pytest tests/ -x` passes (existing tests unbroken)
- `npx tsc --noEmit` passes in frontend
- docker-compose.yml parses without errors
</verification>

<success_criteria>
Article model has scoring fields. UserPreferences model and table exist. Preferences CRUD endpoints work. Categories endpoint returns unique categories from articles. Frontend types and API functions updated. Ollama service in Docker Compose. All existing tests pass.
</success_criteria>

<output>
After completion, create `.planning/phases/04-llm-content-curation/04-01-SUMMARY.md`
</output>
